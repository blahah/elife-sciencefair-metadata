{"title":"Segregation of complex acoustic scenes based on temporal coherence","author":[{"surname":"Teki","given-names":"Sundeep"},{"surname":"Chait","given-names":"Maria"},{"surname":"Kumar","given-names":"Sukhbinder"},{"surname":"Shamma","given-names":"Shihab"},{"surname":"Griffiths","given-names":"Timothy D"}],"abstract":"In contrast to the complex acoustic environments we encounter everyday, most studies of auditory segregation have used relatively simple signals. Here, we synthesized a new stimulus to examine the detection of coherent patterns (‘figures’) from overlapping ‘background’ signals. In a series of experiments, we demonstrate that human listeners are remarkably sensitive to the emergence of such figures and can tolerate a variety of spectral and temporal perturbations. This robust behavior is consistent with the existence of automatic auditory segregation mechanisms that are highly sensitive to correlations across frequency and time. The observed behavior cannot be explained purely on the basis of adaptation-based models used to explain the segregation of deterministic narrowband signals. We show that the present results are consistent with the predictions of a model of auditory perceptual organization based on temporal coherence. Our data thus support a role for temporal coherence as an organizational principle underlying auditory segregation.","identifier":[{"type":"publisher-id","id":"00699"},{"type":"doi","id":"10.7554/eLife.00699"}],"date":{"day":"23","month":"07","year":"2013"},"license":"http://creativecommons.org/licenses/by/3.0/","path":"00699","entryfile":"elife-00699-v1.xml","files":["elife-00699-fig1-v1-600w.jpg","elife-00699-fig2-v1-600w.jpg","elife-00699-fig3-figsupp1-v1-600w.jpg","elife-00699-fig3-v1-600w.jpg","elife-00699-fig4-v1-600w.jpg"]}