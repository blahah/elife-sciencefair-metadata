{"title":"Optimal multisensory decision-making in a reaction-time task","author":[{"surname":"Drugowitsch","given-names":"Jan"},{"surname":"DeAngelis","given-names":"Gregory C"},{"surname":"Klier","given-names":"Eliana M"},{"surname":"Angelaki","given-names":"Dora E"},{"surname":"Pouget","given-names":"Alexandre"}],"abstract":"Humans and animals can integrate sensory evidence from various sources to make decisions in a statistically near-optimal manner, provided that the stimulus presentation time is fixed across trials. Little is known about whether optimality is preserved when subjects can choose when to make a decision (reaction-time task), nor when sensory inputs have time-varying reliability. Using a reaction-time version of a visual/vestibular heading discrimination task, we show that behavior is clearly sub-optimal when quantified with traditional optimality metrics that ignore reaction times. We created a computational model that accumulates evidence optimally across both cues and time, and trades off accuracy with decision speed. This model quantitatively explains subjects's choices and reaction times, supporting the hypothesis that subjects do, in fact, accumulate evidence optimally over time and across sensory modalities, even when the reaction time is under the subject's control.","identifier":[{"type":"publisher-id","id":"03005"},{"type":"doi","id":"10.7554/eLife.03005"}],"date":{"day":"14","month":"06","year":"2014"},"license":"http://creativecommons.org/licenses/by/4.0/","path":"03005","entryfile":"elife-03005-v2.xml","files":["elife-03005-fig1-v2-600w.jpg","elife-03005-fig2-figsupp1-v2-600w.jpg","elife-03005-fig2-v2-600w.jpg","elife-03005-fig3-figsupp1-v2-600w.jpg","elife-03005-fig3-figsupp2-v2-600w.jpg","elife-03005-fig3-v2-600w.jpg","elife-03005-fig4-v2-600w.jpg","elife-03005-fig5-v2-600w.jpg","elife-03005-fig6-v2-600w.jpg","elife-03005-fig7-figsupp1-v2-600w.jpg","elife-03005-fig7-figsupp2-v2-600w.jpg","elife-03005-fig7-v2-600w.jpg","elife-03005-v1.xml"]}