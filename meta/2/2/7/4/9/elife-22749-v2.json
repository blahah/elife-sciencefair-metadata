{"title":"Neural markers of predictive coding under perceptual uncertainty revealed with Hierarchical Frequency Tagging","author":[{"surname":"Gordon","given-names":"Noam"},{"surname":"Koenig-Robert","given-names":"Roger"},{"surname":"Tsuchiya","given-names":"Naotsugu"},{"surname":"van Boxtel","given-names":"Jeroen JA"},{"surname":"Hohwy","given-names":"Jakob"}],"abstract":"There is a growing understanding that both top-down and bottom-up signals underlie perception. But it is not known how these signals integrate with each other and how this depends on the perceived stimuli’s predictability. ‘Predictive coding’ theories describe this integration in terms of how well top-down predictions fit with bottom-up sensory input. Identifying neural markers for such signal integration is therefore essential for the study of perception and predictive coding theories. To achieve this, we combined EEG methods that preferentially tag different levels in the visual hierarchy. Importantly, we examined intermodulation components as a measure of integration between these signals. Our results link the different signals to core aspects of predictive coding, and suggest that top-down predictions indeed integrate with bottom-up signals in a manner that is modulated by the predictability of the sensory input, providing evidence for predictive coding and opening new avenues to studying such interactions in perception.","identifier":[{"type":"publisher-id","id":"22749"},{"type":"doi","id":"10.7554/eLife.22749"}],"date":{"day":"28","month":"02","year":"2017"},"license":"http://creativecommons.org/licenses/by/4.0/","path":"22749","entryfile":"elife-22749-v2.xml","files":["elife-22749-fig1-v2-600w.jpg","elife-22749-fig2-v2-600w.jpg","elife-22749-fig3-figsupp1-v2-600w.jpg","elife-22749-fig3-v2-600w.jpg","elife-22749-fig4-v2-600w.jpg","elife-22749-fig5-v2-600w.jpg","elife-22749-fig6-v2-600w.jpg","elife-22749-v1.xml"]}